{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Character Level LSTM Text Generator  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains character by character on text, and then generates new text character by character.  The training is done with the public domain text of Leo Tolstoi's novel Anna Karenina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "Load in the training book text and encode it as numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Beginning of text:  Chapter 1\n\n\nHappy families are all alike; every un  ...\n--------------------\nBeginning of encoded:  [33 73 42  9 32 18 51 29 52 15 15 15 39 42  9  9 36 29 26 42  5 58  6 58 18\n 53 29 42 51 18 29 42  6  6 29 42  6 58 23 18 40 29 18 38 18 51 36 29 63 66]  ...\n"
    }
   ],
   "source": [
    "# Read file\n",
    "with open(\"anna_karenina_text.txt\") as bk:\n",
    "    txt = bk.read()\n",
    "\n",
    "# Map each character to intergers and provide 2 way mapping dictionaries\n",
    "chars = tuple(set(txt))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {char: i for i, char in int2char.items() }\n",
    "encoded = np.array([char2int[char] for char in txt])\n",
    "\n",
    "# Sanity Check:\n",
    "print(\"Beginning of text: \", txt[:50], \" ...\")\n",
    "print(\"--------------------\")\n",
    "print(\"Beginning of encoded: \", encoded[:50], \" ...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess inputs to be one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(array, nr_labels):\n",
    "    '''\n",
    "    Function to create one-hot encoded array where each characted is one hot-encoded as a column \n",
    "    '''\n",
    "\n",
    "    # Creat array\n",
    "    one_hot_array = np.zeros((np.multiply(*array.shape), nr_labels), dtype=np.float32)\n",
    "    #one_hot_array = np.zeros((np.multiply(*array.shape), nr_labels), dtype=np.long)\n",
    "\n",
    "    # Fill in ones\n",
    "    one_hot_array[np.arange(one_hot_array.shape[0]), array.flatten()] = 1\n",
    "\n",
    "    one_hot_array = one_hot_array.reshape((*array.shape, nr_labels))\n",
    "\n",
    "    return one_hot_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the training data into mini-batches and sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(array, nr_sequences, nr_steps):\n",
    "    ''' \n",
    "    Create batches with number of sequences (nr_sequences) & number of steps (nr_steps) from array\n",
    "    '''\n",
    "    # Size of one batch\n",
    "    batch_size = nr_sequences * nr_steps\n",
    "\n",
    "    # How many batches can be made\n",
    "    nr_batches = len(array) // batch_size\n",
    "\n",
    "    # Crop to integer multiple of batches\n",
    "    array = array[: nr_batches * batch_size]\n",
    "    \n",
    "    # Reshape\n",
    "    array = array.reshape((nr_sequences, -1))\n",
    "\n",
    "    # Loop to create sequences\n",
    "    for i in range(0, array.shape[1], nr_steps):\n",
    "        x = array[:, i:i + nr_steps]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1: ], array[:, i + nr_steps]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1: ], array[:, 0]\n",
    "        yield x,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on batches and sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "x:\n[[33 73 42  9 32 18 51 29 52 15]\n [29 42  5 29 66 71 32 29 16 71]\n [38 58 66 34 15 15 70 69 18 53]\n [66 29 24 63 51 58 66 16 29 73]\n [29 58 32 29 58 53 27 29 53 58]\n [29 12 32 29 56 42 53 15 71 66]\n [73 18 66 29 43 71  5 18 29 26]\n [40 29 61 63 32 29 66 71 56 29]\n [32 29 58 53 66 65 32 34 29 79]\n [29 53 42 58 24 29 32 71 29 73]]\ny:\n[[73 42  9 32 18 51 29 52 15 15]\n [42  5 29 66 71 32 29 16 71 58]\n [58 66 34 15 15 70 69 18 53 27]\n [29 24 63 51 58 66 16 29 73 58]\n [58 32 29 58 53 27 29 53 58 51]\n [12 32 29 56 42 53 15 71 66  6]\n [18 66 29 43 71  5 18 29 26 71]\n [29 61 63 32 29 66 71 56 29 53]\n [29 58 53 66 65 32 34 29 79 73]\n [53 42 58 24 29 32 71 29 73 18]]\n"
    }
   ],
   "source": [
    "batches = create_batches(encoded, 10, 50)\n",
    "x, y = next(batches)\n",
    "print(\"x:\")\n",
    "print(x[:10, :10])\n",
    "print(\"y:\")\n",
    "print(y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class characterLSTM(nn.Module):\n",
    "    '''\n",
    "    Character Level Text Generator LSTM\n",
    "    '''\n",
    "    def __init__(self, chars, nr_steps = 100, nr_hidden = 256, nr_layers = 2, dropout_prob = 0.5, lr = 0.001):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.nr_layers = nr_layers\n",
    "        self.nr_hidden = nr_hidden\n",
    "        self.lr = lr\n",
    "\n",
    "        # Make mapping dictionaries\n",
    "        self.chars = chars\n",
    "        self.int2char = dict(enumerate(chars))\n",
    "        self.char2int = {char: i for i, char in self.int2char.items() }\n",
    "\n",
    "        # LSTM Cell Definition\n",
    "        self.lstm = nn.LSTM(len(self.chars), self.nr_hidden, self.nr_layers, dropout = self.dropout_prob, batch_first = True)\n",
    "\n",
    "        # Add dropout layer to reduce likelihood of overfitting\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "\n",
    "        # Final linear fully connected layer for output\n",
    "        self.fc = nn.Linear(self.nr_hidden, len(self.chars))\n",
    "\n",
    "        # Initialize weights\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x, hc):\n",
    "        '''\n",
    "        Forward pass thru the network with inputs (x) and hidden cell state (hc)\n",
    "        '''\n",
    "\n",
    "        # Get x and hidden state from LSTM\n",
    "        x, (h, c) = self.lstm(x, hc)\n",
    "\n",
    "        # Pass thru dropout\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Stack up LSTM outputs\n",
    "        print(\"x.size()[0] before: \", x.size()[0])\n",
    "        print(\"x.size()[1] before: \", x.size()[1])\n",
    "        print(\"self.nr_hidden: \", self.nr_hidden)\n",
    "        # x = x.view(x.size()[0] * x.size()[1], self.nr_hidden)\n",
    "        x = x.reshape(x.size()[0] * x.size()[1], self.nr_hidden)\n",
    "        print(\"x.size()[0] after: \", x.size()[0])\n",
    "        print(\"x.size()[1] after: \", x.size()[1])\n",
    "\n",
    "        # Pass thru fully connected layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # Return x and hidden state\n",
    "        return x, (h, c)\n",
    "\n",
    "    def predict(self, char, h=None,  top_k=None):\n",
    "        '''\n",
    "        Predict next character\n",
    "        '''\n",
    "\n",
    "        if h is None:\n",
    "            h = self.initialize_hidden_layer(1)\n",
    "\n",
    "        x = np.array([[self.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(self.chars))\n",
    "        \n",
    "        # Convert to input Tensor\n",
    "        inputs = torch.from_numpy(x).type(torch.FloatTensor)\n",
    "\n",
    "        # Run forward pass\n",
    "        h = tuple([each.data for each in h])\n",
    "        out, h = self.forward(inputs, h)\n",
    "    \n",
    "        # Run thru Softmax\n",
    "        p = F.softmax(out, dim=1).data\n",
    "\n",
    "        if top_k is None:\n",
    "            top_char = np.arange(len(self.chars))\n",
    "        else:\n",
    "            p, top_char = p.topk(top_k)\n",
    "            top_char = top_char.numpy().squeeze()\n",
    "\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_char, p = p/p.sum())\n",
    "\n",
    "        return self.int2char[char], h\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        ''' \n",
    "        Initialize fully connected layer weights \n",
    "        '''\n",
    "        \n",
    "        # Set bias tensor = 0\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        # Random fully connected weights\n",
    "        self.fc.weight.data.uniform_(-1, 1)\n",
    "        \n",
    "    def initialize_hidden_layer(self, nr_sequences):\n",
    "        ''' \n",
    "        Initializes hidden state \n",
    "        '''\n",
    "        # Tensors with sizes nr_layers x nr_sequences x nr_hidden initialzied to zero\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.nr_layers, nr_sequences, self.nr_hidden).zero_(),\n",
    "                weight.new(self.nr_layers, nr_sequences, self.nr_hidden).zero_())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_data, nr_epochs=10, nr_sequences=10, nr_steps=50, lr=0.001, gradient_clip=5, val_data_fraction=0.1, print_every=10):\n",
    "    ''' \n",
    "    Train the network     \n",
    "    '''\n",
    "    \n",
    "    net.train()\n",
    "    # Use Adam and Cross Entropy Loss\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Separate data and validation data\n",
    "    val_idx = int(len(train_data) * (1-val_data_fraction) )\n",
    "    train_data, val_data = train_data[:val_idx], train_data[val_idx:]\n",
    "        \n",
    "    counter = 0\n",
    "    nr_chars = len(net.chars)\n",
    "    for e in range(nr_epochs):\n",
    "        h = net.initialize_hidden_layer(nr_sequences)\n",
    "        for x, y in create_batches(train_data, nr_sequences, nr_steps):\n",
    "            counter += 1\n",
    "            #print(\"type(x): \", type(x))\n",
    "            #print(\"x.shape: \", x.shape)\n",
    "\n",
    "            # One-hot encode train_data\n",
    "            x = one_hot_encode(x, nr_chars)\n",
    "            #print(\"after one_hot_encode:\")\n",
    "            #print(\"type(x): \", type(x))\n",
    "            #print(\"x.shape: \", x.shape)\n",
    "            #print(\"type(x[0,0,0]): \", type(x[0,0,0]))\n",
    "            \n",
    "            # Convert to Tensor\n",
    "            inputs, targets = torch.from_numpy(x).type(torch.LongTensor), torch.from_numpy(y).type(torch.LongTensor)\n",
    "            print(\"type(inputs): \", type(inputs))\n",
    "            print(\"inputs.shape: \", inputs.shape)            \n",
    "\n",
    "            # New variables for the hidden state\n",
    "            h = tuple([each.data for each in h])\n",
    "            print(\"type(h): \", type(h))\n",
    "            print(\"type(h[0]):\", type(h[0]))\n",
    "            print(\"h: \", h)\n",
    "            net.zero_grad()\n",
    "            \n",
    "            # Forward Pass\n",
    "            output, h = net.forward(inputs, h)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, targets.view(nr_sequences * nr_steps))\n",
    "\n",
    "            # Back propagate\n",
    "            loss.backward()\n",
    "            \n",
    "            # Use clip_grad_norm to prevent exploding gradient problem\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), gradient_clip)\n",
    "\n",
    "            opt.step()\n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "                \n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(nr_sequences)\n",
    "                val_losses = []\n",
    "                for x, y in create_batches(val_data, nr_sequences, nr_steps):\n",
    "                    # One-hot encode data\n",
    "                    x = one_hot_encode(x, nr_chars)\n",
    "                    # Conver to Tensors\n",
    "                    x, y = torch.from_numpy(x).type(torch.FloatTensor), torch.from_numpy(y).type(torch.FloatTensor)\n",
    "                    \n",
    "                    # New variables for the hidden state\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "\n",
    "                    output, val_h = net.forward(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets.view(nr_sequences * nr_steps))                \n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                print(\"Epoch #: {}/{}...\".format(e+1, nr_epochs),\n",
    "                      \"Step #: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Validation Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do actual training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "characterLSTM(\n  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc): Linear(in_features=512, out_features=83, bias=True)\n)\n"
    }
   ],
   "source": [
    "# Clean up old stuff\n",
    "if 'net' in locals():\n",
    "    del net\n",
    "\n",
    "# Instantiate new network\n",
    "net = characterLSTM(chars, nr_hidden=512, nr_layers=2)\n",
    "\n",
    "# Print the network\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "type(inputs):  <class 'torch.Tensor'>\ninputs.shape:  torch.Size([128, 100, 83])\ntype(h):  <class 'tuple'>\ntype(h[0]): <class 'torch.Tensor'>\nh:  (tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]]))\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-5c6ce3095b9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnr_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnr_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnr_sequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnr_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnr_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-121-f5dc480ecb7e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, train_data, nr_epochs, nr_sequences, nr_steps, lr, gradient_clip, val_data_fraction, print_every)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m# Forward Pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;31m# Calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-34ed28f14d0d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hc)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Get x and hidden state from LSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# Pass thru dropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Py\\Anaconda3_x64\\envs\\cvnd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Py\\Anaconda3_x64\\envs\\cvnd\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 570\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #3 'mat2' in call to _th_addmm_out"
     ]
    }
   ],
   "source": [
    "nr_sequences = 128\n",
    "nr_steps = 100\n",
    "\n",
    "# Train\n",
    "train(net, encoded, nr_epochs=1, nr_sequences = nr_sequences, nr_steps = nr_steps, lr=0.001, print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"lstm_try_1.net\"\n",
    "\n",
    "checkpoint = {'nr_hidden': net.nr_hidden,\n",
    "              'nr_layers': net.nr_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'chars': net.chars}\n",
    "\n",
    "with open(model_name, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "model_name = \"lstm_try_1.net\"\n",
    "with open(model_name, 'rb') as f:\n",
    "    checkpoint = torch.load(f)\n",
    "\n",
    "loaded_net = characterLSTM(checkpoint['chars'], nr_hidden = checkpoint['nr_hidden'], nr_layers = checkpoint['nr_layers'])\n",
    "loaded_net.load_state_dict(checkpoint['state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(net, size, prime='In the beginning', top_k=None):\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    # Start with prime characters\n",
    "    chars = [c for c in prime]\n",
    "    h = net.initialize_hidden_layer(1)\n",
    "    for c in prime:\n",
    "        char, h = net.predict(c, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    # Pass in previous character and generate the next\n",
    "    for i in range(size):\n",
    "        char, h = net.predict(chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden: 512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nx.size()[0]:  1\nx.size()[1]:  1\nseld.nr_hidden:  512\nIn the beginning?D??Qbbm?bm?b?!Qb!!DQD?b?b!mQ(b?!!m!D?QD?bbDbm!bm!(Qjbm!mb!bmmQQbDjbDQQjZQb?!DbDmbbbb!DDDjZZZbmbQjDDQDj?ZDDb!m!D?Q?DDDbZbZDbj!mQ?bDbbDjbj!mbQDD?ZQDQb?QQjbDjm?!???Qb!bDDQQb?Dbbm!DmbbjDDbjmD!bbbbmm?!??!(Q!mbD!D?!!QQ?QQ?bDbmD?DbbDbDDDbbjm!QQDD??bZZZ?DD!ZbQQjbbjmbDDQDQDjD?DbDZQQZ??Zb!!bf(?!bbD?Q?DbQQ?b!QbjbDbm!m?DDb!mbQ?Dbbjm!!DQDQ?Q??QZQ?ZQ?QZQ??Db!Q?D?ZbbbD!bjDmbmbbjDm!Q?DDDbQj?D?ZDQbbD!DQQQbQbb!bD!Qjm??QbbbbbDjDbDZm?!DbDDbbbmbjmbb!?bDbDb!mD!bmDQjb?b?DDZDDDDbbbm!b?D?ZZQ?bQQbjbDDZbmQ?bQQjjbmm!D!?QDD?ZDDQDZbZbZ?DbbDmbbDmj?DQ?ZQQQ?DD?DDD?DDDQ?ZDZQD??DbQbm!bDmb!bDmQb?DDDQQ?QbQjjbbD!Q?bbm?DQQbQjjmDm??DZQbQbD!!!mbDbmDDjQ?ZD?Q?ZZb?!D!!D!m(DDbbbj!?D?bZmQbQj?Qb?Q?bbDjZD?bD!QbQbb!mmDbbmbm!(b!b?b?(?!?Q?bbDmQQbbDj?bDbmm!?DbQD?Q?ZbZbDZZZ?bQQDQQb?Qb?bmbDDj?QZbmb??!!Q?bQ?!DD??QbDb!DmQbDb!DmDQjjZ?D?QQbm!b!DDjDDbjbbDDjbZ???DDQQDQbDbQQD?D?Zb!mb!bmDQDbD?QQZDQQDbDDZZZDZbDDQbZ?DDDbbbm!!DQDj?QQQD?b!D!QDQjjbZbDDbQjDbDjbDmD?Z??Zbbbmm!DQQjDQ?QDQQbDjZZmQbbbm!DQQ?D?bQ?QZ?QbQQQbQj?DD?Q?QZQZQDQbb!bm!DDb!bDQQQDDbj?QDZ?D?b!QDQDbb!jbmDQbbmDbQ?QDDjDD??QQbDDjQ???QQQjZ?QQZ?ZQQ?Z?b!QDmDjQbQQDDjbb!b!DDbbb!!m!bbm(mQDjDZ?bZbD!DmDDbDZ?QZZQ?ZQ??bZDQQ?DZQZbbjfDDmDb?QD?Z?Zb?b!DDm!?!?Q(!!!bDmmDbb!bbm!mDDbDDQjZb??DD!Zb!Qbbb!mmDbD!QDjZDDQ?QZQQ?Q?Qbb?!Q?Q?bQ?QDZb!bmDQ?DQQDjbb!?bm!Qmb!b?b?bbbmbbbjbbb!bbjDmbmQj!QmQbDD?D?bDQ?ZbZm!bm(bDQ?DQ??Qb!??D!?DDD?DZ?D?bZDDDZZ?DZD?QZQD?bbbDDjQbQbj?b!!Qbb!bbmmQj???bDbmQ!D?b!Qmm!DDQjQDZZDZDDZQDjQDZ??bbbDDQjQ?Q?b??bQ?!bDQmQjj?DbDZDbDZQbbmbDj!b?DQDDQjZQDbb!D!DDZbQbDbbDDQbQ?ZQQ?ZDZb!mD?DZZbZ?bQb!!mQ?Qb?D!!!mDQjbmQDjQDZZZQZQZbfm?bbmb??QQZ?QDQZQDDDDDDZZQZ?ZQDDDZQbZ??ZDQbZm!!DDbbbmDD!QDb?!b!bmbD!!DbmQbbj!bDmbDj!bD!Q?bQQQDjQ?b?!DQm!bbjbffbfmm(??b?DD!?bQ?DD?DbQ??bDQbQjQ?bQ?bb?DZbb!!m!DDbb!!!Dm(??b?DbbmmQD?QDZQQQQbDDDQbjD?ZQZQQDQQ?ZbDZQ??DQ??b!QbmbbDjbDjZDDZbDZZbZZZZbfbD!DQbDDDbj?QD?DZQQZbDjbmmDb!mQQDbQjbb!f?mbD?D???QDQZ?Zb!b!m!b!b(DjDZDDZQbbm!bDm?DQ?ZbZ?b!!bbfD(b!bmbbj?mDb!m!???DZ?DZ?bZ?Z?bDDD!ZZ?Q?bbQDj?bZb?Z?!!(bmbDbDjb?!!Db!mDbb!mb?Qbbbjbm!!Q?DQj?Z?b?!bbbDDDbQjbmDDDZDbZbDbjbmDQDbbjmb?DD\n"
    }
   ],
   "source": [
    "print(generate(net, 2000, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}